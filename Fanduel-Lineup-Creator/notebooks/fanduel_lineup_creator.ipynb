{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from basketball_reference_web_scraper import client\n",
    "import joblib\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import Table, Column, String, MetaData, Integer, Float\n",
    "import os\n",
    "from pulp import *\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.environ['RDS_NBA_DATABASE_USER']\n",
    "password = os.environ['RDS_NBA_DATABASE_PASSWORD']\n",
    "\n",
    "db_cleaned_data = create_engine(f'postgresql://{user}:{password}@fanduel-lineup-prediction-cleaned-data.cvzkizpca2fx.us-east-1.rds.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eric\\.conda\\envs\\fanduel-app\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Load player_slugs_names and team abbreviations and team full names from saved joblib objects\n",
    "\n",
    "player_slugs_names = joblib.load('../joblib_objects/player_slugs_names')\n",
    "team_abbreviations_full_name_dict = joblib.load('../joblib_objects/team_abbreviations_full_name_dict')\n",
    "player_label_encoder = joblib.load('../joblib_objects/player_label_encoder')\n",
    "team_label_encoder = joblib.load('../joblib_objects/team_label_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Advanced Analytics\n",
    "\n",
    "advanced_analytics_table = pd.read_csv('../cleaned_data/advanced_analytics/advanced_analytics_total.csv',index_col=0)\n",
    "advanced_analytics_columns = advanced_analytics_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define features\n",
    "base_features = [\n",
    "    'FD_pts_scored', 'location', 'opponent_id', 'points_scored',\n",
    "    'seconds_played', 'made_field_goals', 'attempted_field_goals',\n",
    "    'made_three_point_field_goals', 'attempted_three_point_field_goals',\n",
    "    'made_free_throws', 'attempted_free_throws', 'offensive_rebounds',\n",
    "    'defensive_rebounds', 'assists', 'steals', 'blocks', 'turnovers',\n",
    "    'game_score', 'rest', 'no_rest', '1_day_rest', '2_day_rest', '3_day_rest',\n",
    "    '4_day_rest', '5_day_rest', '5_plus_day_rest', 'Simple_Rating_System',\n",
    "    'Offensive_Rating', 'Defensive_Rating', 'Net_Rating', 'Pace',\n",
    "    'Free_Throw_Rate', '3_Pt_Rate', 'Turnover_Percentage',\n",
    "    'Offensive_Rebound_Percentage', 'Opponent_EFG',\n",
    "    'Opponent_Turnover_Percentage', 'Opponent_Defensive_Rebound_Percentage'\n",
    "]\n",
    "\n",
    "past_7_features = [\n",
    "    'points_scored', 'seconds_played', 'made_field_goals',\n",
    "    'attempted_field_goals', 'made_three_point_field_goals',\n",
    "    'attempted_three_point_field_goals', 'made_free_throws',\n",
    "    'attempted_free_throws', 'offensive_rebounds', 'defensive_rebounds',\n",
    "    'assists', 'steals', 'blocks', 'turnovers', 'game_score'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove accents and symbols from strings\n",
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_contest_csv(csv_file):\n",
    "\n",
    "    #Load csv\n",
    "    contest_df = pd.read_csv(csv_file, index_col=0)\n",
    "    contest_df = contest_df.rename(columns={'Id': 'FD_player_ID'})\n",
    "    contest_df = contest_df.loc[contest_df['Injury Indicator'] != 'O', :]\n",
    "\n",
    "    #Filter columns, format nickname and add player slugs based on nickname\n",
    "    contest_df = contest_df[['FD_player_ID','Position','Nickname','FPPG','Salary','Game','Opponent']]\n",
    "    contest_df['Nickname'] = contest_df['Nickname'].apply(lambda x: x.replace('.',''))\n",
    "    contest_df['Nickname'] = contest_df['Nickname'].apply(lambda x: f\"{x.split(' ')[0]} {x.split(' ')[1]}\")\n",
    "    contest_df['slug'] = contest_df['Nickname'].apply(lambda x: player_slugs_names[x])\n",
    "\n",
    "    # Add binary location column (0 for home, 1 for away)\n",
    "    contest_df['location'] = ''\n",
    "    for i in range(len(contest_df)):\n",
    "        home_team = contest_df['Game'].iloc[i].split('@')[1]\n",
    "        if contest_df['Opponent'].iloc[i] == home_team:\n",
    "            location = 1\n",
    "        else:\n",
    "            location = 0\n",
    "\n",
    "        contest_df['location'].iloc[i] = location\n",
    "\n",
    "    #Convert opponent abbreviation to full team name formatted for team label encoder\n",
    "    contest_df['Opponent'] = contest_df['Opponent'].apply(lambda x: team_abbreviations_full_name_dict[x])\n",
    "\n",
    "    #Create two columns with opponent id and player id\n",
    "    contest_df['Opponent_ID'] = contest_df['Opponent'].apply(lambda x: team_label_encoder.transform([x])[0])\n",
    "    contest_df['player_ID'] = contest_df['slug'].apply(lambda x: player_label_encoder.transform([x])[0])\n",
    "\n",
    "    return contest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to retrieve model features dataframe for player which includes past week averages and total averages\n",
    "def get_historic_features(df):\n",
    "\n",
    "    historic_features = {}\n",
    "\n",
    "    df_past_7_games = df.iloc[-7:]\n",
    "\n",
    "    for feature in past_7_features:\n",
    "        historic_features[f'{feature}_last_7'] = [df_past_7_games[feature].mean()]\n",
    "    \n",
    "    for feature in past_7_features:\n",
    "        historic_features[f'{feature}_average'] = [df[feature].mean()]\n",
    "\n",
    "    historic_features_df = pd.DataFrame(historic_features)\n",
    "\n",
    "    return historic_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_player_fdpoints(slug, location, opponent_id):\n",
    "\n",
    "    #Load player csv data\n",
    "    df = pd.read_sql_table(slug, db_cleaned_data, index_col='index')\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    if len(df) > 5:\n",
    "\n",
    "        #Define required features from historic data\n",
    "        X_features = [\n",
    "            'points_scored_last_7', 'seconds_played_last_7',\n",
    "            'made_field_goals_last_7', 'attempted_field_goals_last_7',\n",
    "            'made_three_point_field_goals_last_7',\n",
    "            'attempted_three_point_field_goals_last_7', 'made_free_throws_last_7',\n",
    "            'attempted_free_throws_last_7', 'offensive_rebounds_last_7',\n",
    "            'defensive_rebounds_last_7', 'assists_last_7', 'steals_last_7',\n",
    "            'blocks_last_7', 'turnovers_last_7', 'game_score_last_7',\n",
    "            'points_scored_average', 'seconds_played_average',\n",
    "            'made_field_goals_average', 'attempted_field_goals_average',\n",
    "            'made_three_point_field_goals_average',\n",
    "            'attempted_three_point_field_goals_average',\n",
    "            'made_free_throws_average', 'attempted_free_throws_average',\n",
    "            'offensive_rebounds_average', 'defensive_rebounds_average',\n",
    "            'assists_average', 'steals_average', 'blocks_average',\n",
    "            'turnovers_average', 'game_score_average'\n",
    "        ]\n",
    "\n",
    "        #Use get_historic_features function to get historic data and retrieve most recent game with only X features columns\n",
    "        most_recent_game = get_historic_features(df)\n",
    "        most_recent_game_date = df.iloc[-1]['date']\n",
    "\n",
    "        #Get days of rest by calculting from most recent game date\n",
    "        current_date = datetime.datetime.now()\n",
    "        days_rest = (current_date - most_recent_game_date).days - 1\n",
    "\n",
    "        #Create dataframe starting with location and opponent ID\n",
    "        location_opponent_id_df = pd.DataFrame({\n",
    "            'location': [location],\n",
    "            'Opponent_ID': [opponent_id]\n",
    "        })\n",
    "\n",
    "        #Add rest columns\n",
    "        location_opponent_id_df['no_rest'] = 1 if days_rest == 0 else 0\n",
    "        location_opponent_id_df['1_day_rest'] = 1 if days_rest == 1 else 0\n",
    "        location_opponent_id_df['2_day_rest'] = 1 if days_rest == 2 else 0\n",
    "        location_opponent_id_df['3_day_rest'] = 1 if days_rest == 3 else 0\n",
    "        location_opponent_id_df['4_day_rest'] = 1 if days_rest == 4 else 0\n",
    "        location_opponent_id_df['5_day_rest'] = 1 if days_rest == 5 else 0\n",
    "        location_opponent_id_df['5_plus_day_rest'] = 1 if days_rest > 5 else 0\n",
    "\n",
    "        #Get advanced analytics from opponent ID\n",
    "        opponent_id = location_opponent_id_df['Opponent_ID'].iloc[0]\n",
    "        analytics = advanced_analytics_table.loc[\n",
    "            (advanced_analytics_table['year'] == 2019) &\n",
    "            (advanced_analytics_table['Team_ID'] == opponent_id),\n",
    "            advanced_analytics_columns[2:]]\n",
    "        analytics = analytics[[\n",
    "            'Simple_Rating_System', 'Offensive_Rating', 'Defensive_Rating',\n",
    "            'Net_Rating', 'Pace', 'Free_Throw_Rate', '3_Pt_Rate',\n",
    "            'Turnover_Percentage', 'Offensive_Rebound_Percentage', 'Opponent_EFG',\n",
    "            'Opponent_Turnover_Percentage', 'Opponent_Defensive_Rebound_Percentage'\n",
    "        ]]\n",
    "\n",
    "        #Concatenate 3 dataframes into one then produce values as list\n",
    "        prediction_series = pd.concat([location_opponent_id_df.iloc[0], analytics.iloc[0], most_recent_game.iloc[0]])\n",
    "        prediction_df = pd.DataFrame(prediction_series.to_dict(),index=[0])\n",
    "        prediction_testing_array = prediction_df.values\n",
    "        \n",
    "        #Load MinMaxScaler based on slug and transform values \n",
    "        scaler = joblib.load(f'../scalers/{slug}_scaler')\n",
    "\n",
    "        prediction_testing_array = scaler.transform(prediction_testing_array)\n",
    "\n",
    "        #Get prediction by loading model based on slug and using prediction_testing_array to produce prediction\n",
    "        player_xgb_model = joblib.load(f'../models/{slug}_model.dat')\n",
    "        prediction = player_xgb_model.predict(prediction_testing_array)\n",
    "\n",
    "        return prediction\n",
    "    \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full_lineup(csv_file):\n",
    "\n",
    "    #Load formatted contest csv into pandas dataframe\n",
    "    contest_df = format_contest_csv(csv_file)\n",
    "\n",
    "    predictions_df = pd.DataFrame(columns=['slug','pts_spread','position','salary'])\n",
    "    for slug in contest_df:\n",
    "        #Predict fd_pts and compare to projection based on fd listed salary\n",
    "        fd_pts_prediction = predict_player_fdpoints(contest_df['slug'])\n",
    "        player_position = contest_df['Position']\n",
    "        pts_projection = (contest_df['Salary'] / 1000) * 5\n",
    "        pts_spread = (fd_pts_prediction - pts_projection) / 10\n",
    "\n",
    "        #Add row to predictions_df\n",
    "        predictions_df.append({'slug':contest_df['slug'], 'pts_spread':pts_spread,\n",
    "                                'position':player_position, 'salary':contest_df['Salary']},ignore_index=True)\n",
    "\n",
    "        #Create top value df\n",
    "        sorted_predictions_df = predictions_df.sort_values('pts_spread',ascending=True)\n",
    "\n",
    "        #Create top value dfs for each position\n",
    "        sorted_predictions_pg_df = predictions_df.loc[predictions_df['position'] == 'PG'].sort_values('pts_spread',ascending=True).iloc[:5]\n",
    "        sorted_predictions_sg_df = predictions_df.loc[predictions_df['position'] == 'SG'].sort_values('pts_spread',ascending=True).iloc[:5]\n",
    "        sorted_predictions_sf_df = predictions_df.loc[predictions_df['position'] == 'SF'].sort_values('pts_spread',ascending=True).iloc[:5]\n",
    "        sorted_predictions_pf_df = predictions_df.loc[predictions_df['position'] == 'PF'].sort_values('pts_spread',ascending=True).iloc[:5]\n",
    "        sorted_predictions_c_df = predictions_df.loc[predictions_df['position'] == 'C'].sort_values('pts_spread', ascending=True).iloc[:5]\n",
    "\n",
    "        # List of FD positions.\n",
    "        FD_POSITION_LIST = ['PG', 'SG', 'PF', 'SF', 'C']\n",
    "        salaries = predictions_df['Salary'].to_numpy()\n",
    "        values = predictions_df['pts_spread'].to_numpy()\n",
    "\n",
    "def get_lineup(csv_file):\n",
    "\n",
    "    contest_df = format_contest_csv(csv_file)\n",
    "\n",
    "    predictions_df = pd.DataFrame(columns=[\n",
    "        'slug', 'projected_fd_pts',\n",
    "        'pts_spread', 'position', 'salary'\n",
    "    ])\n",
    "\n",
    "    for i in range(len(contest_df)):\n",
    "\n",
    "        try:\n",
    "\n",
    "            #Define parameters for player\n",
    "            slug = contest_df.iloc[i]['slug']\n",
    "            location = contest_df.iloc[i]['location']\n",
    "            position = contest_df.iloc[i]['Position']\n",
    "            salary = contest_df.iloc[i]['Salary']\n",
    "            opponent_id = contest_df.iloc[i]['Opponent_ID']\n",
    "\n",
    "            #Predict player projection and get pts_spread\n",
    "            prediction = predict_player_fdpoints(slug, location, opponent_id)[0]\n",
    "            pts_projection = (salary / 1000) * 5\n",
    "            pts_spread = (prediction - pts_projection) / 10\n",
    "\n",
    "            #Add new row to predictions\n",
    "            predictions_df = predictions_df.append(\n",
    "                {\n",
    "                    'slug': slug,\n",
    "                    'projected_fd_pts': prediction,\n",
    "                    'pts_spread': pts_spread,\n",
    "                    'position': position,\n",
    "                    'salary': salary\n",
    "                },\n",
    "                ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    #Create top value df\n",
    "    sorted_predictions_df = predictions_df.sort_values('pts_spread', ascending=False)\n",
    "\n",
    "    #Create top value dfs for each position\n",
    "    pgs = predictions_df.loc[predictions_df['position'] == 'PG'].sort_values('pts_spread', ascending=False).iloc[:6]\n",
    "    sgs = predictions_df.loc[predictions_df['position'] == 'SG'].sort_values('pts_spread', ascending=False).iloc[:6]\n",
    "    sfs = predictions_df.loc[predictions_df['position'] == 'SF'].sort_values('pts_spread', ascending=False).iloc[:6]\n",
    "    pfs = predictions_df.loc[predictions_df['position'] == 'PF'].sort_values('pts_spread', ascending=False).iloc[:6]\n",
    "    cs = predictions_df.loc[predictions_df['position'] =='C'].sort_values('pts_spread',ascending=False).iloc[:4]\n",
    "\n",
    "    return predictions_df,pgs,sgs,sfs,pfs,cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eric\\.conda\\envs\\fanduel-app\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "predictions_df,pgs,sgs,sfs,pfs,cs = get_lineup('../test_contest/test_contest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgs = predictions_df.loc[predictions_df['position'] == 'PG'].values\n",
    "sgs = predictions_df.loc[predictions_df['position'] == 'SG'].values\n",
    "sfs = predictions_df.loc[predictions_df['position'] == 'SF'].values\n",
    "pfs = predictions_df.loc[predictions_df['position'] == 'PF'].values\n",
    "cs = predictions_df.loc[predictions_df['position'] == 'C'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = {}\n",
    "points = {}\n",
    "for position in [pgs,sgs,sfs,pfs,cs]:\n",
    "    \n",
    "    player_salaries = {}\n",
    "    player_points = {}\n",
    "    position_dictionary_key = position[0][3]\n",
    "    \n",
    "    for player in position:\n",
    "        \n",
    "        player_salaries[player[0]] = player[4]\n",
    "        player_points[player[0]] = player[2]\n",
    "        \n",
    "    salaries[position_dictionary_key] = player_salaries\n",
    "    points[position_dictionary_key] = player_points\n",
    "\n",
    "pos_num_available = {\n",
    "    \"PG\": 2,\n",
    "    \"SG\": 2,\n",
    "    \"SF\": 2,\n",
    "    \"PF\": 2,\n",
    "    \"C\": 1\n",
    "}\n",
    "\n",
    "SALARY_CAP = 60000\n",
    "MINIMUM_SALARY_USE = 59000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vars = {k: LpVariable.dict(k, v, cat=\"Binary\") for k, v in points.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = LpProblem(\"Fantasy\", LpMaximize)\n",
    "rewards = []\n",
    "costs = []\n",
    "position_constraints = []\n",
    "# Setting up the reward\n",
    "for k, v in _vars.items():\n",
    "    costs += lpSum([salaries[k][i] * _vars[k][i] for i in v])\n",
    "    rewards += lpSum([points[k][i] * _vars[k][i] for i in v])\n",
    "    prob += lpSum([_vars[k][i] for i in v]) == pos_num_available[k]\n",
    "    \n",
    "prob += lpSum(rewards)\n",
    "prob += lpSum(costs) <= SALARY_CAP\n",
    "prob += lpSum(costs) >= MINIMUM_SALARY_USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(prob):\n",
    "    div = '---------------------------------------\\n'\n",
    "    print(\"Variables:\\n\")\n",
    "    score = str(prob.objective)\n",
    "    constraints = [str(const) for const in prob.constraints.values()]\n",
    "    for v in prob.variables():\n",
    "        score = score.replace(v.name, str(v.varValue))\n",
    "        constraints = [const.replace(v.name, str(v.varValue)) for const in constraints]\n",
    "        if v.varValue != 0:\n",
    "            print(v.name, \"=\", v.varValue)\n",
    "    print(div)\n",
    "    print(\"Constraints:\")\n",
    "    for constraint in constraints:\n",
    "        constraint_pretty = \" + \".join(re.findall(\"[0-9\\.]*\\*1.0\", constraint))\n",
    "        if constraint_pretty != \"\":\n",
    "            print(\"{} = {}\".format(constraint_pretty, eval(constraint_pretty)))\n",
    "    print(div)\n",
    "    print(\"Score:\")\n",
    "    score_pretty = \" + \".join(re.findall(\"[0-9\\.]+\\*1.0\", score))\n",
    "    print(\"{} = {}\".format(score_pretty, eval(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "\n",
      "C_jokicni01 = 1.0\n",
      "PF_tatumja01 = 1.0\n",
      "PF_theisda01 = 1.0\n",
      "PG_lowryky01 = 1.0\n",
      "SF_anunoog01 = 1.0\n",
      "SF_brownja02 = 1.0\n",
      "SG_mitchdo01 = 1.0\n",
      "SG_vanvlfr01 = 1.0\n",
      "---------------------------------------\n",
      "\n",
      "Constraints:\n",
      "9800*1.0 + 9000*1.0 + 5300*1.0 + 7500*1.0 + 5200*1.0 + 6300*1.0 + 8500*1.0 + 7600*1.0 = 59200.0\n",
      "9800*1.0 + 9000*1.0 + 5300*1.0 + 7500*1.0 + 5200*1.0 + 6300*1.0 + 8500*1.0 + 7600*1.0 = 59200.0\n",
      "---------------------------------------\n",
      "\n",
      "Score:\n",
      "0.42271728515625*1.0 + 0.158734130859375*1.0 + 0.16667709350585938*1.0 + 0.6119556427001953*1.0 + 0.7240589141845704*1.0 + 0.41717071533203126*1.0 + 0.34461669921875*1.0 + 0.05333366394042969*1.0 = 1.452540969848633\n"
     ]
    }
   ],
   "source": [
    "prob.solve()\n",
    "\n",
    "summary(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in prob.variables():\n",
    "    \n",
    "    score = str(prob.objective)\n",
    "    constraints = [str(const) for const in prob.constraints.values()]\n",
    "    score = score.replace(v.name, str(v.varValue))\n",
    "    constraints = [const.replace(v.name, str(v.varValue)) for const in constraints]\n",
    "    \n",
    "    if v.varValue != 0:\n",
    "        v_str_split = str(v).split('_')\n",
    "        slug = v_str_split[1]\n",
    "        position = v_str_split[0]\n",
    "        \n",
    "        player = player_slugs_then_names[slug]\n",
    "        salary = salaries[position][slug]\n",
    "        \n",
    "        new_row = {\n",
    "            'Player':player,\n",
    "            'Salary':salary,\n",
    "            'Position':position\n",
    "        }\n",
    "        \n",
    "        optimized_lineup_df = optimized_lineup_df.append(new_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_lineup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
